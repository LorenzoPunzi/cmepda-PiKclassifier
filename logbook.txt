Logbook for CMEPDA final assignment     Ruben Forti / Lorenzo Punzi

09/01/22:

Abbiamo creato il repository con il Logbook.

Possiamo approfondire la questione della continuous integration per il testing e sphynx per la documentazione.

Abbiamo discusso un po' la separation power per introdurla ed eventualmente discuterla nel lavoro

Abbiamo delineato una prima potenziale parte del progetto (aka BOLDf). Questa ha lo scopo di paragonare direttamente una DNN al BoldR usato in morelloproject. Si fa uso solo di Mpipi e si applica ai dati generati con la frazione nota già misurata in morelloproject.

BOLDf:
1) Usare i MC per generare un set di "dati" con una frazione nota, ad esempio 0.5 che è sia vicina a quella target ed è unbiased a priori. Nel generarli salvare quali dati sono K (y=1) e quali Pi (y=0) per il training
2) Trainare la DNN su questo set di dati
3) Applicare la DNN ai "dati originali" e SOMMARE le yi ottenute su tutti gli eventi. Questa somma viene presa come il numero MEDIO di K nel sample di dati. Questo approccio ha il vantaggio di non fregarsene di ogni evento individuale ma di fare un "valore atteso totale" del numero di K, contando ogni evento pesandolo con probabilità di essere K, quindi per convenzione K=1. Ciò dovrebbe essere anche corretto nel caso (realissimo) in cui le probabilità NON sono fra loro indipendenti, tanto il valore atteso della somma è sempre la somma dei valori attesi. Quindi invece di fare una DNN con uscita {False,True} o trasformare le yi reali in 0 o 1 con un qualche criterio, PRESERVIAMO l'informazione data da un valore intermedio pesandolo come tale nella somma (In un certo senso è come se ogni evento ti dicesse "se tutti gli eventi sono come me f = yi", e si facesse una media di questi valori pesando tutti gli eventi ugualmente).
4) Si paragona la frazione così ottenuta con quella di BoldR. Bisognerà un po' esplorare il problema dell'incertezza da legare a questa stima. Per esempio noi calcoliamo il valore medio, ma se davvero fossero per esempio tutte massimamente correlate le probabilità potrebbe in linea di principio dare un valore di f intermedio anche quando nella realtà è molto vicino a 0 o 1....

Si possono estendere queste tecniche anche con un training su più frazioni invece di solo 0.5, eventualmente trainando la DNN su frazioni diverse e minimizzando la loss tenendo conto anche di questo iperparametro

Quanto detto fin'ora in linea di principio è fattibile con il solo Python, eventualmente PyRoot, ed eventualmente anche il JITing di C++ all'interno.


-----------------------------------------------------------------

11/01/22:

Iniziato il modulo import_functions, contenente le funzioni che permettono di
arrivare ad ottenere un array da sottoporre al training.

Utilizzato uproot per trasformare i dati dei tree in array numpy: oltre ad essere
più flessibile (permette di dare in input anche il nome della variabile desiderata),
impiega 1/3 del tempo della funzione costruita "a mano".

Le altre due funzioni servono per valori casuali dalle distribuzioni, assegnare
la flag ad ogni evento e fare un merge degli array delle due specie.

Per queste funzioni vanno scritti unit tests e documentazione

Queste funzioni sono utilizzate in dataset.py


12/01/22:

Documentazione delle prime funzioni fatta. Impostato il primo unit test (vedere
se va bene o è migliorabile), secondo u.t. da fare

16/01/22:

C'è un problema concettuale: Noi facciamo quello che vogliamo ma alla fine anche se si trovasse perfettamente la frazione di pi e K ( i.e. separazione perfetta) COMUNQUE non è la vera f, ma solo una variabile binomiale che IN MEDIA fa f (questo è il significato della sigma_best nel potere di separazione). Questa cosa non era stata chiarita in morelloproject, ma è fondamentale ricordare che f misurata NON è f0 ma una variabile a sua volta.

Si può fare eventualmente un bootstrap per misurare la varianza del nostro stimatore neurale finale, sennò considerare la somma delle varianze dei contributi yi

TH1::GetRandom ha il vantaggio di non dover tirarsi fuori un template ma ha lo svantaggio di essere distribuito non come la distribuzione ma come la pdf*U[binwidth] e inoltre i contents di ogni bin non sono che una poissoniana che in media fa l'integrale della pdf in quel bin---> fluttuazioni per sample size finita. Questi effetti sistematici se si usa GetRandom vanno quantomeno menzionati

Bisogna capire che generatori random usare dato che TRandom si basa su Rndm che a quanto pare NON va usato in studi statistici

Chiameremo f0 (f PURE) la frazione media da cui provengono le distribuzioni, mentre quella effettiva (f EFFECTIVE) è quella effettiva di K su pi sul sample LIMITATO di eventi

Consideriamo oltre che alle classiche stragie di functional programming la possibilità di costruire delle classi ibride array-TH1 ad hoc per potersi giostrare velocemente fra le due specie

Per il disegno per esempio potremmo creare una UNICA funzionzione arrtohist che converte uno nell'altro capendo che tipo è l'argomento e restituendo l'altro tipo di conseguenza

17/01/23:

Creiamo il training.py inizialmente per array di sola UNA colonna di dati (+ 1 di flag). Poi lavoreremo a generalizzare ad array a più colonne, cioè quando si usano multiple varibles per il training e la evaluation.
Sorge subito un problema: il training restituisce lo stesso valore per tutte gli inputs del data sample, o quantomeno sbaglia di molto (anche trainando su 0.5 e applicandolo a 0.4) e dà yi tutte molto vicine fra loro.
Questo potrebbe essere dovuto al fatto che gli stiamo dando soltanto una variabile in input. dovremmo provare a testare con due colonne, cioè due variabili.

19/01/23:

20/01/23 (incontro Rizzi):

Innanzitutto la somma dei valori yi in uscita non è un buono stimatore (come ha dimostrato Rizzi). Perciò sarà necessario fare un template fit sulla distribuzione di y in uscita dei dati usando come template le distribuzioni y dei dati di training.

Cose da fare:
    - Rimettere a posto i file .py nella cartella data/
    - Template fit/sistema lineare a valle della DNN
    - Cornerplot per vedere la separazioni fra variabili
    - Moduli per template fit classico / sistema lineare classico
    - Perfezionare la DNN
    - Boost decision tree
    - Grafico RoC per varie strategie




21/01/23 (Ruben):

Creata cartella contenente gli scripts per il template fit classico. L'upload
dei dataset conviene farlo con RDataFrame che è agilissimo e evita di fare
esplicitamente loop e dichiarazioni inutili di variabili (boilerplate addiòs)

Il fit non è terminato e l'organizzazione delle funzioni è da migliorare, ad
ora la cartella contiene:
  - template_fit.py -> funzioni di base per i fit dei due dataset mc
    e poi per il fit congiunto dati i rispettivi output (parametri di fit che
    si passano comodamente tra funzioni)
  - plot_utilities.py -> modulo che dovrebbe raccogliere funzioni comode per
    fare i plot degli istogrammi con sopra i fit: andrà implementato anche un
    subplot per i residui e andrà migliorata la schermata con le informazioni
    del fit (parametri, chi2, prob)



30/01/23 (Ruben):

Template fit sui montecarlo sono ultimati (andrebbe rivisto quanto sono affidabili,
cioè se il fit è robusto rispetto a piccole variazioni nel range ecc). Il fit sui
dati è impostato ma va perfezionato.

Ciao da Elia

I comandi da eseguire per compilare la shared library, dati i file header.h e
sourcefile.cpp, sono:
    gcc -c -fpic fit_functions.cpp `root-config --cflags --glibs` -o fit_functions
    gcc -shared -fpic -o func_library.so fit_functions


31/01/23 (Lorenzo e Ruben):

Abbiamo trovato un piccolo errore nel template fit e siamo riusciti a trovare il valore "giusto" per f.

Lorenzo ha problemi a montare le .so, ma non a usarle se già create...

Le priorità ora sono capire corner.py e il template fit a valle della DNN (se questa si riesce a far funzionare bene).



03/02/23 (Lorenzo):

Ho creato il file cornerplot.py per fare i corner plot. Devo mandare in input
array a più variabili di soli pi o soli k dai mc, e per farlo bisognerà fare uno
script utilizzando la funzione loadvars in import_functions.py, che non ricordo
chi ha scritto (ps: è stato Ruben). Non mi sembra che venga usata in nessuno
degli script presenti (ps: era usata nel main di import_functions stessa),
quindi la provo a usare.

Inoltre non capisco bene la differenza fra data_gen e training_set, sembrano fare
più o meno la stessa cosa. Non ho capito chi è stato a generare i multivariable
array xxxx_array_prova.txt (ps: è stato import_functions nel main, vedi sopra).
Tra l'altro data_gen ha un serio problema, la funzione prende solo due argomenti
mentre gliene viene dati 3 (anche f0) nel main.

Infine dataset.py non capisco a cosa serva, se è obsoleto cancelliamolo. Lo stesso
dataset_generation.py, che però vedo che è più recente. (ps: A quanto pare possono
entrambe essere cancellate)


04/02/23 (Lorenzo):

Ho rinominato /template_fit/import_functions.py come /template_fit/template_functions.py
modificando anche l'import in /template_fit/template_fit.py, così da non confondersi
con /data/import_functions.py

Potrebbe essere opportuno rinominare la cartella /data --> /arraygen dato che è
forse più pertinente come nome

Per qualche motivo non funziona if __name__ == '__main__' in corner.py, devo fare diretto...

Ho fatto corner.py, in particolare due funzioni: una fa il corner plot dato un
array, l'altra date liste di array fanno un corner plot sovrapposto degli array.

Ho runnato il cornerplot sovrapposto per tutte le scelte possibili di variabili
e praticamente tutte apparte le M0_Mxx sembrano troppo simili fra i pi e i k: QUESTO È UN SERIO PROBLEMA.
Ho salvato le varie combinazioni come immagini per poterle vedere in seguito.



05/02/23 (Ruben):

I corner plot in effetti non sono molto promettenti, ma ci sono un paio di cose
che si possono tentare:
    - nelle correlazioni tra q.tà cinematiche delle singole particelle, il massimo
      di alcune distribuzioni (tutte escluso eta) è diverso per i due dataset.
      Ora, i due MC raccolgono un numero leggermente diverso di eventi (differenza
      di circa 1000), ma questo effetto nelle distribuzioni può essere dovuto a
      una effettiva differenza di comportamento nelle due specie?
    - possiamo provare a valutare nuove variabili correlando quelle esistenti:
      ad esempio si potrebbe fare "M_p + M_KK", "M_p - M_PiPi" ecc (tutto ciò
      si fa velocemente con RDataFrame). La composizione di queste nuove variabili
      si basa sui plot di correlazione prodotti con corner, l'obbiettivo è di creare
      delle "slices" in tali plot dove si renda maggiormente evidente la distinzione
      tra regione rossa e blu


09/02/23 (Ruben):

Piccoli aggiustamenti alle funzioni nella cartella /data:
    - il nome della cartella per ora lo lascerei così perché sarebbero da cambiare
      i path dei file ovunque. Questo non è un problema ma va tenuta comunque attenzione
      alla questione dei path per sviluppare (alla fine) un sistema flessibile per
      raggiungere i file con i dati (es. funzione os.path)
    - nuova funzione dummy "array_to_txt" in import_functions (per sgravare così il
      main da inutili righe di codice ----> da fare)
    - funzioni in import_functions classificate in base al loro utilizzo























----------------- IDEA GENERALE PROGETTO ---------------------

--- I/O DATA CON ROOT (RDF ove possibile)
--- FIT ROOT CLASSICO
--- ML:
    - DNN
    - BDT
--- PLOT---> TH1,CORNER,ROC
--- UNIT TEST
--- DOC (SPHYNX)
*** CONFRONTO RISULTATI



------------------------------- QUESTIONS -----------------------------

* How should the function modules be organized? Should we use only one module with all the functions? Or group related ones together?

* Can we/ should we use multiprocessing in one point or another?
